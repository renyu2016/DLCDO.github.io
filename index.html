<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Autonomous Manipulation Learning for Similar Deformable Objects
via Only One Demonstration</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>




<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Autonomous Manipulation Learning for Similar Deformable Objects
            via Only One Demonstration</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              Yu Ren</a><sup>1,2,3</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=NH4NtmMAAAAJ&hl=zh-CN&oi=ao">Ronghan Chen</a><sup>1,2,3</sup>,</span>
            <span class="author-block">
              <a href="http://ai.sia.cn/">Yang Cong</a><sup>1,2</sup>,
            </span>

          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>State Key Laboratory of Robotics, Shenyang Institute of Automation, Chinese Academy of Sciences,</span>
            <span class="author-block"><sup>2</sup>Institutes for Robotics and Intelligent Manufacturing, Chinese Academy of Sciences</span>
            <span class="author-block"><sup>3</sup>University of Chinese Academy of Sciences, Beijing, 100049, China</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>

              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/renyu2016/DLCDO"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://mailustceducn-my.sharepoint.com/:f:/g/personal/renyu20_mail_ustc_edu_cn/Enx5_Al1xDBAhFQSJhPe_MEB4C4VuyCNp0xKPMOWPY1iAQ?e=N03FsM"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">

      <img src="./static/images/overall_framework.jpg"
                 class="interpolation-image"
                 alt="Interpolation end reference image."/>
            <p class="is-bold"></p>

      <h2 class="subtitle has-text-centered">
        <span class="dnerf"></span>Overall workflow of our developed framework, which could learn manipulation skills via only once demonstration and generalize the learned skills to novel instances without any re-training.
      </h2>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            In comparison with most methods focusing on 3D rigid
            object recognition and manipulation, deformable objects
            are more common in our real life but attract less attention.
            Generally, most existing methods for deformable object ma-
            nipulation suffer two issues, 1) Massive demonstration: re-
            peating thousands of robot-object demonstrations for model
            training of one specific instance; 2) Poor generalization:
            inevitably re-training for transferring the learned skill to
            a similar/new instance from the same category. There-
            fore, we propose a category-level deformable 3D object ma-
            nipulation framework, which could manipulate deformable
            3D objects with only one demonstration and generalize the
            learned skills to new similar instances without re-training.
            Specifically, our proposed framework consists of two mod-
            ules. The Nocs State Transform (NST) module transfers the
            observed point clouds of the target to a pre-defined uni-
            fied pose state (i.e., Nocs state), which is the foundation for
            the category-level manipulation learning; the Neural Spa-
            tial Encoding (NSE) module generalizes the learned skill to
            novel instances by encoding the category-level spatial in-
            formation to pursue the expected grasping point without
            re-training. The relative motion path is then planned to
            achieve autonomous manipulation. Both the simulated re-
            sults via our Cap40dataset1and real robotic experiments
            justify the effectiveness of our framework.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-2">Video</h2>
      </div>
    </div>
    <!--/ Paper video. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">

      <!-- Wearing cap-Simulation. -->
      <div class="column">
        <div class="content">
          <h2 class="title is-3">Wearing cap-Simulation</h2>
          <p>
            We demonstrate the wearing cap skill once time and test the learned skill with different caps in pybullet(simulation).
          </p>
          <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/simulated_result.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
      <!--/ Visual Effects. -->

      <!-- Wearing cap-Real world. -->
      <div class="column">
        <h2 class="title is-3">Wearing cap-Real world</h2>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              We demonstrate the wearing cap skill once time and test the learned skill with different caps in real-world system.
            </p>
            <video id="matting-video" controls playsinline height="100%">
              <source src="./static/videos/real_scense.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div>
      <!-- Wearing cap-Real world. -->
    </div>

    <div class="columns is-centered">

      <!--Hangcap-Real world. -->
      <div class="column">
        <div class="content">
          <h2 class="title is-3">Hanging cap-Real world</h2>
          <p>
            We demonstrate the hanging cap skill once time and test the learned skill with different caps in real-world system.
          </p>
          <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/hangcaptask.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
      <!--/ Hangcap-Real world. -->

      <!-- Geometry generalization ability. -->
      <div class="column">
        <h2 class="title is-3">Geometry generalization</h2>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              We test the learned hanging cap skill with the caps have significant geometry diversity.
            </p>
            <video id="matting-video" controls playsinline height="100%">
              <source src="./static/videos/geometric_generalization.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div>

    </div>
    <!--/ Geometry generalization ability. -->


  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{rencvpr23,
  author    = {Yu, Ren and Ronghan, Chen and Yang},
  title     = {Autonomous Manipulation Learning for Similar Deformable Objects via Only One Demonstration},
  journal   = {CVPR},
  year      = {2023},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
